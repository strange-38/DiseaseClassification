{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "554a39ad-79b8-4976-a11e-939863d03af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b9373bca-1d08-4edd-8262-37298d61732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Read CSV normally\n",
    "df = pd.read_csv(\"preprocessed_medical_abstracts.csv\")\n",
    "\n",
    "# ‚úÖ Convert stringified list back to real Python list\n",
    "df['tokens_no_stopwords'] = df['tokens_no_stopwords'].apply(ast.literal_eval)\n",
    "\n",
    "# üîÅ Recreate token_string\n",
    "df['token_string'] = df['tokens_no_stopwords'].apply(\n",
    "    lambda sents: ' '.join([word for sent in sents for word in sent])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "f371f9c2-a4a0-4568-90ee-1245539cfc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tissue change loose prosthesis canine model investigate effect antiinflammatory agent aseptically loosen prosthesis provide means investigate vivo vitro activity cell associate loosening process seven\n"
     ]
    }
   ],
   "source": [
    "print(df['token_string'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "946307f2-767d-4a9c-9e98-0f1591e88a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "df['label_enc'] = le.fit_transform(df['condition_label'])\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['token_string'].tolist(), df['label_enc'].tolist(), test_size=0.2, random_state=42, stratify=df['label_enc'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "168fa47f-7cae-4f8b-828d-f55dc2810536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: comparison cardiac catheterization doppler echocardiography decision operate aortic mitral valve disease clinical decision utilize doppler echocardiographic cardiac catheterization datum compare adult patient isolated combine aortic mitral valve disease clinical decision operate operate remain uncertain experienced cardiologist doppler echocardiographic cardiac catheterization datum prospective evaluation perform consecutive patient mean age year valvular heart disease consider surgical treatment basis clinical information patient undergo cardiac catheterization detailed doppler echocardiographic examination set cardiologist decision maker know patient identity clinical information combination doppler echocardiographic cardiac catheterization datum combination doppler echocardiographic clinical datum consider inadequate clinical decision making patient aortic patient mitral valve disease combination cardiac catheterization clinical datum consider inadequate patient aortic patient mitral valve disease remain patient cardiologist use echocardiographic angiographic datum agreement decision operate operate overall datum analyze specific valve lesion decision base doppler echocardiography catheterization agreement respectively patient aortic regurgitation mitral stenosis aortic stenosis mitral regurgitation difference cardiac output determination estimation valvular regurgitation information concern coronary anatomy main reason different clinical management decision result suggest adult patient aortic mitral valve disease combination doppler echocardiographic datum enable clinician decision reach catheterization datum\n",
      "Label: 3\n",
      "---\n",
      "Text: angiographic change suggestive vasospasm migraine complicate stroke year old woman history common migraine develop permanent leave homonymous hemianopia typical headache ct scan demonstrate right posterior cerebral infarction angiography irregular narrowing ipsilateral posterior cerebral artery suggestive vasospasm case risk factor atherosclerotic stroke present smoking cause stroke find\n",
      "Label: 2\n",
      "---\n",
      "Text: spontaneous pneumoperitoneum surgical dilemma pneumoperitoneum usually result hollow viscus perforation associated peritonitis nonsurgical spontaneous pneumoperitoneum incidental intrathoracic intra abdominal gynecologic iatrogenic miscellaneous cause associate perforate viscus document literature seven case spontaneous pneumoperitoneum admit year period grady memorial hospital atlanta georgia report patient pneumoperitoneum undergo exploratory laparotomy clinical examination suggest acute abdomen intra abdominal pathology document patient seventh patient ventilatory support manage conservatively perform diagnostic peritoneal lavage negative case radiographically misdiagnose pneumoperitoneum pneumoperitoneum precede reasonable incidental cause patient adequate abdominal examination warrant continue observation avoid unnecessary laparotomy\n",
      "Label: 1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Text: {train_texts[i]}\")\n",
    "    print(f\"Label: {train_labels[i]}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd85f27-b1c5-4ac2-9a6a-635c092cfe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=200)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "35afe9ed-b790-43fa-a03d-98813387ae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: [101, 7831, 15050, 4937, 27065, 11124, 9276, 2079, 9397, 3917, 9052, 11522, 26535, 3247, 5452, 20118, 28228, 2278, 10210, 7941, 10764, 4295, 6612, 3247, 16462, 2079, 9397, 3917, 9052, 11522, 3695, 14773, 15050, 4937, 27065, 11124, 9276, 23755, 2819, 12826, 4639, 5776, 7275, 11506, 20118, 28228, 2278, 10210, 7941, 10764, 4295, 6612, 3247, 5452, 5452, 3961, 9662, 5281, 4003, 20282, 22522, 2079, 9397, 3917, 9052, 11522, 3695, 14773, 15050, 4937, 27065, 11124, 9276, 23755, 2819, 17464, 9312, 4685, 5486, 5776, 2812, 2287, 2095, 11748, 19722, 8017, 2540, 4295, 5136, 11707, 3949, 3978, 6612, 2592, 5776, 13595, 15050, 4937, 27065, 11124, 9276, 6851, 2079, 9397, 3917, 9052, 11522, 3695, 14773, 7749, 2275, 4003, 20282, 22522, 3247, 9338, 2113, 5776, 4767, 6612, 2592, 5257, 2079, 9397, 3917, 9052, 11522, 3695, 14773, 15050, 4937, 27065, 11124, 9276, 23755, 2819, 5257, 2079, 9397, 3917, 9052, 11522, 3695, 14773, 6612, 23755, 2819, 5136, 14710, 6612, 3247, 2437, 5776, 20118, 28228, 2278, 5776, 10210, 7941, 10764, 4295, 5257, 15050, 4937, 27065, 11124, 9276, 6612, 23755, 2819, 5136, 14710, 5776, 20118, 28228, 2278, 5776, 10210, 7941, 10764, 4295, 3961, 5776, 4003, 20282, 22522, 2224, 9052, 11522, 3695, 14773, 17076, 3695, 14773, 23755, 2819, 3820, 3247, 5452, 102]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Decoded back: [CLS] comparison cardiac catheterization doppler echocardiography decision operate aortic mitral valve disease clinical decision utilize doppler echocardiographic cardiac catheterization datum compare adult patient isolated combine aortic mitral valve disease clinical decision operate operate remain uncertain experienced cardiologist doppler echocardiographic cardiac catheterization datum prospective evaluation perform consecutive patient mean age year valvular heart disease consider surgical treatment basis clinical information patient undergo cardiac catheterization detailed doppler echocardiographic examination set cardiologist decision maker know patient identity clinical information combination doppler echocardiographic cardiac catheterization datum combination doppler echocardiographic clinical datum consider inadequate clinical decision making patient aortic patient mitral valve disease combination cardiac catheterization clinical datum consider inadequate patient aortic patient mitral valve disease remain patient cardiologist use echocardiographic angiographic datum agreement decision operate [SEP]\n"
     ]
    }
   ],
   "source": [
    "# View first example\n",
    "print(\"Input IDs:\", train_encodings['input_ids'][0])\n",
    "print(\"Attention Mask:\", train_encodings['attention_mask'][0])\n",
    "print(\"Decoded back:\", tokenizer.decode(train_encodings['input_ids'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ab7fa6b0-6681-4f8b-92eb-993ec41cd834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClinicalDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: torch.tensor(val[idx]) for key, val in self.encodings.items()\n",
    "        } | {\"labels\": torch.tensor(self.labels[idx])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9bf8923c-2e3b-451b-a3cc-40f7880621e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ClinicalDataset(train_encodings, train_labels)\n",
    "val_dataset = ClinicalDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "818cbf1d-c979-403b-a326-8bde141ea4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.ClinicalDataset object at 0x7011a3e4c0d0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397f002-8126-4a9f-bbd2-39e90c9aa7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(le.classes_)\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "# ‚úÖ Replace the classifier to increase dropout\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),  # üëà increased from 0.1 to 0.3\n",
    "    nn.Linear(model.config.hidden_size, len(le.classes_))\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# ‚úÖ Freeze the first 6 layers\n",
    "for name, param in model.bert.encoder.layer[:6].named_parameters():\n",
    "    param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e059dfa-8f34-47cb-9e8a-a828d1e7a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = AdamW([\n",
    "    {'params': model.bert.parameters(), 'lr': 5e-6},  # üëà gentler LR for BERT base\n",
    "    {'params': model.classifier.parameters(), 'lr': 2e-5}  # üëà higher LR for new classifier head\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd97c468-7111-4aab-9837-1daf321613e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f25d02-5131-486a-9393-8454782cf92d",
   "metadata": {},
   "source": [
    "## early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1775de5d-60b1-4019-ad52-3db5931b341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | Train Loss: 1.4513\n",
      "Macro F1: 0.5205\n",
      "‚úÖ F1 improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 | Train Loss: 0.9857\n",
      "Macro F1: 0.5703\n",
      "‚úÖ F1 improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 | Train Loss: 0.8628\n",
      "Macro F1: 0.5878\n",
      "‚úÖ F1 improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 | Train Loss: 0.8048\n",
      "Macro F1: 0.5945\n",
      "‚úÖ F1 improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 | Train Loss: 0.7533\n",
      "Macro F1: 0.6017\n",
      "‚úÖ F1 improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 | Train Loss: 0.7075\n",
      "Macro F1: 0.6098\n",
      "‚úÖ F1 improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 | Train Loss: 0.6701\n",
      "Macro F1: 0.5968\n",
      "‚ùó EarlyStopping counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 | Train Loss: 0.6391\n",
      "Macro F1: 0.6126\n",
      "‚úÖ F1 improved. Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 | Train Loss: 0.6049\n",
      "Macro F1: 0.6028\n",
      "‚ùó EarlyStopping counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 | Train Loss: 0.5747\n",
      "Macro F1: 0.5947\n",
      "‚ùó EarlyStopping counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 289/289 [01:09<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11 | Train Loss: 0.5544\n",
      "Macro F1: 0.5946\n",
      "‚ùó EarlyStopping counter: 3/3\n",
      "üõë Early stopping triggered!\n",
      "Training time: 0:13:44.205721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# EarlyStopping class (if you haven't defined it yet)\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_score, model):\n",
    "        if self.best_score is None or val_score > self.best_score:\n",
    "            self.best_score = val_score\n",
    "            self.counter = 0\n",
    "            torch.save(model.state_dict(), \"checkpoint.pt\")  # ‚úÖ Save best model\n",
    "            print(\"‚úÖ F1 improved. Saving model...\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"‚ùó EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# --------------------- Training Loop ---------------------\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "model.train()\n",
    "epochs = 20\n",
    "print(\"Starting training...\")\n",
    "start = datetime.now()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1} | Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # ------------------ Validation ------------------\n",
    "    model.eval()\n",
    "    val_preds, val_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    macro_f1 = f1_score(val_true, val_preds, average='macro')\n",
    "    print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "\n",
    "    early_stopping(macro_f1, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"üõë Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "print(\"Training time:\", datetime.now() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a23f4053-a34f-469b-bc1c-2ac98023a5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=768, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a1cb8205-9ca8-4bb0-aa1d-7302b735ef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Validation Accuracy (best model): 0.6134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74       506\n",
      "           1       0.49      0.74      0.59       239\n",
      "           2       0.49      0.71      0.58       308\n",
      "           3       0.67      0.76      0.71       488\n",
      "           4       0.66      0.33      0.44       769\n",
      "\n",
      "    accuracy                           0.61      2310\n",
      "   macro avg       0.60      0.66      0.61      2310\n",
      "weighted avg       0.63      0.61      0.60      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "val_preds, val_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute final accuracy\n",
    "accuracy = accuracy_score(val_true, val_preds)\n",
    "print(f\"‚úÖ Validation Accuracy (best model): {accuracy:.4f}\")\n",
    "\n",
    "# Optional: F1, Precision, Recall\n",
    "print(classification_report(val_true, val_preds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
